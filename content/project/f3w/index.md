---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Fetch What We Want(FIIIW)"
summary: ""
authors: ["admin"]
tags: ["Robotics", "Computer Vision"]
categories: []
date: 2019-11-14T17:11:32+08:00

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: "Smart"
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code: https://github.com/Wonderful99668/Fetch-What-We-Want
#url_pdf: ""
#url_slides: ""
url_video: https://www.youtube.com/watch?v=WOYQ2A6ZiRU&feature=youtu.be

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

[**F**etch **W**hat **W**e **W**ant(**FIIIW**)](https://github.com/Wonderful99668/Fetch-What-We-Want) is an intelligent Feeding Robot designed specifically for those people who cannot eat or drink independently. 

In this project, I integrated Speech recognition, Face detection, Object detection and Human Computer Interaction algorithms into one single Robotic Arm, which endows the product multiple merits: **easy to use**, **accurate** while **economical.** Robotic Arm can extract key words from user's instruction and fetch corresponding foods(e.g. breads, waters) from table, fed to the patients' mouth. The whole process is done automatically, user's just need to talk to robot to make instructions.